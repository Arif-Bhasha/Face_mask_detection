{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ac9cf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random as rd\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c1694a",
   "metadata": {},
   "source": [
    "## reading the location paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d332b14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_mask = glob.glob(r\"C:\\Users\\HP\\Desktop\\CNN_Articels_clean_2\\mask\\data\\with_mask/*.*\")\n",
    "without_mask = glob.glob(r\"C:\\Users\\HP\\Desktop\\CNN_Articels_clean_2\\mask\\data\\without_mask/*.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8893637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3725"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(with_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f26b913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3828"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(without_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0b97d3",
   "metadata": {},
   "source": [
    "## created new folder for creating new folders of \"d_train\",\"d_test\",\"d_cross_val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58cd2449",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(r\"C:\\Users\\HP\\Desktop\\CNN_Articels_clean_2\\mask\\data\\newdaforagument\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e6580d",
   "metadata": {},
   "source": [
    "## now creating new folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "897cd614",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(r\"C:\\Users\\HP\\Desktop\\CNN_Articels_clean_2\\mask\\data\\newdaforagument\\train\")\n",
    "os.makedirs(r\"C:\\Users\\HP\\Desktop\\CNN_Articels_clean_2\\mask\\data\\newdaforagument\\test\")\n",
    "os.makedirs(r\"C:\\Users\\HP\\Desktop\\CNN_Articels_clean_2\\mask\\data\\newdaforagument\\validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c93ce25",
   "metadata": {},
   "source": [
    "* successfully created new foldes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43b7a7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(r\"C:\\Users\\HP\\Desktop\\CNN_Articels_clean_2\\mask\\data\\newdaforagument\\train\\withmask\")\n",
    "os.makedirs(r\"C:\\Users\\HP\\Desktop\\CNN_Articels_clean_2\\mask\\data\\newdaforagument\\train\\withoutmask\")\n",
    "os.makedirs(r\"C:\\Users\\HP\\Desktop\\CNN_Articels_clean_2\\mask\\data\\newdaforagument\\validation\\withmask\")\n",
    "os.makedirs(r\"C:\\Users\\HP\\Desktop\\CNN_Articels_clean_2\\mask\\data\\newdaforagument\\validation\\withoutmask\")\n",
    "os.makedirs(r\"C:\\Users\\HP\\Desktop\\CNN_Articels_clean_2\\mask\\data\\newdaforagument\\test\\withmask\")\n",
    "os.makedirs(r\"C:\\Users\\HP\\Desktop\\CNN_Articels_clean_2\\mask\\data\\newdaforagument\\test\\withoutmask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0295fad2",
   "metadata": {},
   "source": [
    "## separated 1000 images into d_train without_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e43358b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rd.sample(range(len(without_mask)),k=1000)\n",
    "z = 0\n",
    "z1 = []\n",
    "for i in x:\n",
    "    img = cv2.imread(without_mask[i])\n",
    "    cv2.imwrite(r\"C:\\Users\\HP\\Desktop\\CNN_Articels_clean_2\\mask\\data\\newdaforagument\\train\\withoutmask\\without_mask{}.jpg\".format(z),img)\n",
    "    z=z+1\n",
    "    z1.append(without_mask[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea19ec6",
   "metadata": {},
   "source": [
    "## separates 1000 images into d_train with_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f218752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rd.sample(range(len(with_mask)),k=1000)\n",
    "z = 0\n",
    "z2 = []\n",
    "for i in x:\n",
    "    img = cv2.imread(with_mask[i])\n",
    "    cv2.imwrite(r\"C:\\Users\\HP\\Desktop\\CNN_Articels_clean_2\\mask\\data\\newdaforagument\\train\\withmask\\with_mask{}.jpg\".format(z),img)\n",
    "    z=z+1\n",
    "    z2.append(with_mask[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76b220d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wm1 = set(with_mask).difference(z2)\n",
    "wom1 = set(without_mask).difference(z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f92784ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "wm1 = list(wm1)\n",
    "wom1 = list(wom1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab09654",
   "metadata": {},
   "source": [
    "## separates 500 images into d_crossvalidation without_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb9eb6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = rd.sample(range(len(wom1)),k=500)    \n",
    "z = 0\n",
    "c2 = []\n",
    "for i in y:\n",
    "    img = cv2.imread(wom1[i])\n",
    "    cv2.imwrite(r\"C:\\Users\\HP\\Desktop\\CNN_Articels_clean_2\\mask\\data\\newdaforagument\\validation\\withoutmask\\without_mask{}.jpg\".format(z),img)\n",
    "    z=z+1\n",
    "    \n",
    "    c2.append(wom1[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a711c074",
   "metadata": {},
   "source": [
    "## separates 500 images into d_crossvalidation with_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "105817d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rd.sample(range(len(wm1)),k=500)    \n",
    "z = 0\n",
    "c1 = []\n",
    "for i in x:\n",
    "    img = cv2.imread(wm1[i])\n",
    "    cv2.imwrite(r\"C:\\Users\\HP\\Desktop\\CNN_Articels_clean_2\\mask\\data\\newdaforagument\\validation\\withmask\\with_mask{}.jpg\".format(z),img)\n",
    "    z=z+1\n",
    "    c1.append(wm1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10d4b5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wm2 = set(wm1).difference(c1)\n",
    "wom2 = set(wom1).difference(c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ac7162c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wm2 = list(wm2)\n",
    "wom2 = list(wom2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697ec5df",
   "metadata": {},
   "source": [
    "## separates 500 images into d_test without_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c65ce59",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rd.sample(range(len(wom2)),k=500)    \n",
    "z = 0\n",
    "for i in x:\n",
    "    img = cv2.imread(wom2[i])\n",
    "    cv2.imwrite(r\"C:\\Users\\HP\\Desktop\\CNN_Articels_clean_2\\mask\\data\\newdaforagument\\test\\withoutmask\\without_mask{}.jpg\".format(z),img)\n",
    "    z=z+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035bf1d9",
   "metadata": {},
   "source": [
    "## separates 500 images into d_test with_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a863a9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rd.sample(range(len(wm2)),k=500)    \n",
    "z = 0\n",
    "for i in x:\n",
    "    img = cv2.imread(wm2[i])\n",
    "    cv2.imwrite(r\"C:\\Users\\HP\\Desktop\\CNN_Articels_clean_2\\mask\\data\\newdaforagument\\test\\withmask\\without_mask{}.jpg\".format(z),img)\n",
    "    z=z+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5035ea73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b85a99d",
   "metadata": {},
   "source": [
    "## image generator building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa9ccce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = ImageDataGenerator(\n",
    "rescale=1./255,\n",
    "rotation_range=20,\n",
    "shear_range=0.2,\n",
    "zoom_range=0.2\n",
    ")\n",
    "\n",
    "train_gen = train_data.flow_from_directory(\n",
    "r\"C:\\Users\\HP\\Desktop\\CNN_Articels_clean_2\\mask\\data\\newdaforagument\\train\",\n",
    "target_size=(100,100),\n",
    "batch_size=10,\n",
    "class_mode=\"categorical\")\n",
    "\n",
    "validation_data = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_gen = validation_data.flow_from_directory(\n",
    "r\"C:\\Users\\HP\\Desktop\\CNN_Articels_clean_2\\mask\\data\\newdaforagument\\validation\",\n",
    "target_size=(100,100),\n",
    "batch_size=10,\n",
    "class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0be1f746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Flatten,Dropout\n",
    "from keras.layers import Conv2D,MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2b349b",
   "metadata": {},
   "source": [
    "## building the architechture for best model with agumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3aa49227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 98, 98, 20)        560       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 49, 49, 20)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 49, 49, 10)        5010      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 24, 24, 10)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 20, 20, 60)        15060     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 24000)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 60)                1440060   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 122       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,460,812\n",
      "Trainable params: 1,460,812\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(20,(3,3),padding=\"valid\",activation=\"relu\",input_shape=(100,100,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(10,(5,5),padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(60,(5,5),activation=\"relu\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(60,activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(2,activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7b43dd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6c8e6b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_22724\\733990825.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(train_gen,steps_per_epoch=2000//10,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "200/200 [==============================] - 217s 1s/step - loss: 0.4142 - accuracy: 0.8235 - val_loss: 0.3483 - val_accuracy: 0.8670\n",
      "Epoch 2/3\n",
      "200/200 [==============================] - 78s 389ms/step - loss: 0.2778 - accuracy: 0.8915 - val_loss: 0.2369 - val_accuracy: 0.9070\n",
      "Epoch 3/3\n",
      "200/200 [==============================] - 77s 385ms/step - loss: 0.2192 - accuracy: 0.9225 - val_loss: 0.2705 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20178724640>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_gen,steps_per_epoch=2000//10,\n",
    "epochs=3,\n",
    "validation_data=validation_gen,\n",
    "validation_steps=1000//10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "45816161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_gen = test_data.flow_from_directory(r\"C:\\Users\\HP\\Desktop\\CNN_Articels_clean_2\\mask\\data\\newdaforagument\\test\",\n",
    "target_size=(100,100),\n",
    "batch_size=10,\n",
    "class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "54447895",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_22724\\1326741156.py:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  model.evaluate_generator(test_gen,steps=1000//10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2461686134338379, 0.902999997138977]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(test_gen,steps=1000//10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ad06ae",
   "metadata": {},
   "source": [
    "* with agumentation i have got 90% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297bcbf9",
   "metadata": {},
   "source": [
    "## architechture without data agumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb2377ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "wm  = glob.glob(r\"C:\\Users\\HP\\Desktop\\CNN_Articels_clean_2\\mask\\data\\newdaforagument\\train\\withmask/*.*\")\n",
    "wom = glob.glob(r\"C:\\Users\\HP\\Desktop\\CNN_Articels_clean_2\\mask\\data\\newdaforagument\\train\\withoutmask/*.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cbc05a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "for i in wm:\n",
    "    img = cv2.imread(i)\n",
    "    img = cv2.resize(img, (100,100))\n",
    "    data.append(img)\n",
    "    labels.append(0)\n",
    "    \n",
    "for y in wom:\n",
    "    img1 = cv2.imread(y)\n",
    "    img1 = cv2.resize(img1, (100,100))\n",
    "    data.append(img1)\n",
    "    labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "660f07d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "cv2.imshow(\"img\",data[700])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "print(labels[700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1d1cba43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "13bb95e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(np.array(data),np.array(labels),test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "df802fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.utils\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4a3c13b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trainf = keras.utils.to_categorical(y_train,dtype='int')\n",
    "y_testf = keras.utils.to_categorical(y_test,dtype='int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d560914c",
   "metadata": {},
   "source": [
    "## normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "18f82e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trains = x_train/255\n",
    "x_tests = x_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd0d2d8",
   "metadata": {},
   "source": [
    "## creating a architechture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "727085c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 98, 98, 20)        560       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 49, 49, 20)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 49, 49, 10)        5010      \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 24, 24, 10)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 20, 20, 60)        15060     \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 24000)             0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 60)                1440060   \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 2)                 122       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,460,812\n",
      "Trainable params: 1,460,812\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Conv2D(20,(3,3),padding=\"valid\",activation=\"relu\",input_shape=(100,100,3)))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model2.add(Conv2D(10,(5,5),padding=\"same\",activation=\"relu\"))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model2.add(Conv2D(60,(5,5),activation=\"relu\"))\n",
    "\n",
    "model2.add(Flatten())\n",
    "\n",
    "model2.add(Dense(60,activation=\"relu\"))\n",
    "\n",
    "model2.add(Dense(2,activation=\"softmax\"))\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a8f353",
   "metadata": {},
   "source": [
    "## compiling and trining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d9a19bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6694b222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "112/112 [==============================] - 41s 281ms/step - loss: 0.5208 - accuracy: 0.7339 - val_loss: 0.2673 - val_accuracy: 0.9071\n",
      "Epoch 2/3\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.3511 - accuracy: 0.8580 - val_loss: 0.2165 - val_accuracy: 0.9107\n",
      "Epoch 3/3\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 0.2859 - accuracy: 0.8964 - val_loss: 0.2110 - val_accuracy: 0.9107\n"
     ]
    }
   ],
   "source": [
    "s = model2.fit(x_trains,y_trainf,batch_size=10,epochs=3,verbose=1,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ba0c78",
   "metadata": {},
   "source": [
    "## evaluating the datasets which are unseen by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e3b5d489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 5s 171ms/step - loss: 0.2685 - accuracy: 0.8850\n"
     ]
    }
   ],
   "source": [
    "a = model2.evaluate(x_tests,y_testf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0853b448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2685367465019226, 0.8849999904632568]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50329373",
   "metadata": {},
   "source": [
    "* without agumentation i have got 88% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f914f60a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
